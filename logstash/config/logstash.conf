input {
    lumberjack {
        port            => 5000
        ssl_certificate => "/etc/logstash/conf.d/pki/tls/certs/logstash-forwarder.crt"
        ssl_key         => "/etc/logstash/conf.d/pki/tls/private/logstash-forwarder.key"
        #codec => plain {
                #charset => "ISO-8859-1"
        #}
    }
    redis {
	data_type	 => "list"
     	key		 => "er_base_logger_common"
	host		 => "elk-redis"
    }
    redis {
        type             => "django"
	data_type	 => "list"
     	key		 => "service_logs"
	host		 => "elk-redis"
    }
    redis {
        type             => "user"
	data_type	 => "list"
     	key		 => "user_behavior_record"
	host		 => "elk-redis"
}
    redis {
        type             => "user_action"
	data_type	 => "list"
     	key		 => "user_action"
	host		 => "elk-redis"
}
}
## Add your filters here
# syslog filter
filter {
#  if [type] == "syslog" {
#    grok {
#      match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
#      add_field => [ "received_at", "%{@timestamp}" ]
#      add_field => [ "received_from", "%{host}" ]
#    }
#    syslog_pri { }
#    date {
#      match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
#    }
#  }
#
#  if [type] == "uwsgilog" {
#      grok {
#        patterns_dir => "/etc/logstash/conf.d/patterns"
#        match => { "message" => "%{UWSGIACCESS}" }
#      }
#
#      mutate {
#        remove_field => [ "file", "offset", "timestamp" ]
#      }
#
#      date {
#           match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
#      }
#
#      kv {
#        field_split => "&? "
#        include_keys => [ "file_name", "device_id", "lang", "country"]
#      }
#      geoip {
#        source => "clientip"
#        database => "/etc/logstash/GeoLite2-City.mmdb"
#        fields => ["city_name", "country_name", "latitude", "longitude"]
#        add_field => [ "[geoip][location]", "%{[geoip][longitude]}" ]
#        add_field => [ "[geoip][location]", "%{[geoip][latitude]}"  ]
#        remove_field => ["[geoip][latitude]", "[geoip][longitude]"]
#      }
#      mutate {
#        convert => [ "[geoip][location]", "float"]
#      }
#  }
#
  if [type] == "nginx-access" {
    grok {
      patterns_dir => "/etc/logstash/conf.d/patterns"
      match => { "message" => "%{NGINXACCESS}" }
    }
    date {
          match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]

    }
    geoip {
      source => "clientip"
      fields => ["city_name", "country_code2", "country_name", "latitude", "longitude", "region_name"] remove_field => ["[geoip][latitude]", "[geoip][longitude]"]
      }
  }
  if [type] == "nginx-main" {
    grok {
      patterns_dir => "/etc/logstash/conf.d/patterns"
      match => { "message" => "%{NGINXMAIN}" }
    }
    date {
          match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]

    }
    geoip {
      source => "clientip"
      fields => ["city_name", "country_code2", "country_name", "latitude", "longitude", "region_name"] remove_field => ["[geoip][latitude]", "[geoip][longitude]"]
      }
  }
  if [type] == "nginx-error" {
    grok {
      patterns_dir => "/etc/logstash/conf.d/patterns"
      match => { "message" => [ "%{NGINXERROR1}","%{NGINXERROR2}","%{NGINXERROR3}","%{NGINXERROR4}" ]}
    }
    date {
          match => [ "timestamp" , "yyyy/MM/dd HH:mm:ss" ]
    }
  }
  if [type] == "yishidata" {
    json {
        source => "message"
    }
  }
  if [type] == "baiduyisheng" {
    json {
        source => "message"
    }
  }
  if [type] == "er_base_logger" {
    json {
        source => "data"
    }
    grok {
      patterns_dir => "/etc/logstash/conf.d/patterns"
      match => { "message" => "%{WERKZEUG}" }
    }
    geoip {
      source => "remote_addr"
      fields => ["city_name", "country_code2", "country_name", "latitude", "longitude", "region_name"]
      add_field => ["[geoip][location]", "%{[geoip][longitude]}" ]
      add_field => [ "[geoip][location]", "%{[geoip][latitude]}"  ]
      remove_field => ["[geoip][latitude]", "[geoip][longitude]"]
      }
      mutate {
        convert => [ "[geoip][location]", "float"]
      }

  }
}

output {

  if [type] == "uwsgilog" {
    elasticsearch {
      #DD is day of year, dd is day of month
      index => "soundlife-uwsgi-log-%{+YYYY.MM.dd}"
      hosts => "elasticsearch:9200"
      user => "logstash"
      password => "logstashethica"
      # need to run curl -XPUT localhost:9200/_template/soundlife-template -d ' to apply index to elasticsearch before creating indices on Kibana
      # template => "/etc/logstash/conf.d/soundlife-template.json"
    }
  }
  else if [type] =~ /nginx-*/ {
    elasticsearch {
      index => "nginx-log-%{+YYYY.MM}"
      hosts => "elasticsearch:9200"
      user => "logstash"
      password => "logstashethica"
    }
  }
  else if [type] == "supervisor-main" or [type] == "syslog" {
    elasticsearch {
      index => "system-log-%{+YYYY.MM}"
      hosts => "elasticsearch:9200"
      user => "logstash"
      password => "logstashethica"
    }
  }
  else if [type] == "yishidata" {
    elasticsearch {
      index => "%{index}"
      hosts => "elasticsearch:9200"
      document_id => "%{document_id}"
      document_type => "%{document_type}"
      user => "logstash"
      password => "logstashethica"
    }
  }
  else if [type] == "er_base_logger" {
    elasticsearch {
        hosts => "elasticsearch:9200"
    	index => "%{index}-%{+YYYY.MM.dd}"
        document_type => "%{document_type}"
        user => "logstash"
        password => "logstashethica"
        flush_size => 1024
        idle_flush_time => 10
    }
  }
  else if [type] == "django" {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "%{index}-%{+YYYY.MM.dd}"
        document_type => "%{index}"
        user => "logstash"
        password => "logstashethica"
        flush_size => 1024
        idle_flush_time => 10
    }
  }
  else if [type] == "user" {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "new-%{index}-%{+YYYY.MM.dd}"
        document_type => "%{index}"
        user => "logstash"
        password => "logstashethica"
        flush_size => 1024
        idle_flush_time => 10
    }
  }
  else if [elastic_log_type] == "ethicall_log" {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "%{index}"
        document_type => "%{document_type}"
        document_id => "%{document_id}"
        user => "logstash"
        password => "logstashethica"
    }
  }
  else if [type] == "user_action" {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "page_analytics-%{+YYYY.MM.dd}"
        user => "logstash"
        password => "logstashethica"
    }
  }
  else if [type] == "uat_user_action" {
    elasticsearch {
        hosts => "elasticsearch:9200"
        index => "uat-page_analytics-%{+YYYY.MM.dd}"
        user => "logstash"
        password => "logstashethica"
    }
  }
  else{
    elasticsearch {
      hosts => "elasticsearch:9200"
      user => "logstash"
      password => "logstashethica"
    }
  }
}
